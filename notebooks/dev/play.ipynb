{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os \n",
    "# os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "klin = np.loadtxt('../flowpm/data/Planck15_a1p00.txt').T[0]\n",
    "plin = np.loadtxt('../flowpm/data/Planck15_a1p00.txt').T[1]\n",
    "stages = np.linspace(0.1, 1.0, 5, endpoint=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.interpolate import InterpolatedUnivariateSpline as iuspline\n",
    "\n",
    "ipklin = iuspline(klin, plin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/chirag/.local/lib/python3.6/site-packages/tensorflow_core/python/compat/v2_compat.py:88: disable_resource_variables (from tensorflow.python.ops.variable_scope) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "non-resource variables are not supported in the long term\n"
     ]
    }
   ],
   "source": [
    "import tensorflow.compat.v1 as tf\n",
    "tf.disable_v2_behavior()\n",
    "import mesh_tensorflow as mtf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the cluster\n",
    "# cluster = tf.train.ClusterSpec({\"mesh\": [\"localhost:2222\", \"localhost:2223\"]})\n",
    "\n",
    "# import flowpm.mesh_ops as mpm\n",
    "\n",
    "nblockx = 2\n",
    "nblocky = 2\n",
    "nproc = nblockx*nblocky\n",
    "\n",
    "mesh_hosts = [\"localhost:%d\"%(8222+j) for j in range(nproc)]\n",
    "\n",
    "# Create a cluster from the mesh hosts.                                                                                                                                                                                                                                                                                                                                  \n",
    "cluster = tf.train.ClusterSpec({\"mesh\": mesh_hosts, \"master\":[\"localhost:8488\"]})\n",
    "\n",
    "# Create a server for local mesh members                                                                                                                                                                                                                                                                                                                                 \n",
    "server = tf.train.Server(cluster,\n",
    "                       job_name=\"master\",\n",
    "                       task_index=0)\n",
    "\n",
    "devices = ['/job:mesh/task:%d'%i for i in range(cluster.num_tasks(\"mesh\"))]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.pop(6)\n",
    "sys.path.append('../')\n",
    "sys.path.append('../flowpm/')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import flowpm.mesh_ops as mpm\n",
    "import flowpm\n",
    "from flowpm import mesh_ops\n",
    "from flowpm import mesh_utils\n",
    "from flowpm import mesh_kernels\n",
    "\n",
    "import flowpm.mesh_utils as mpu\n",
    "import flowpm.mtfpm as fpm\n",
    "import tensorflow_probability as tfp\n",
    "\n",
    "\n",
    "graph = mtf.Graph()\n",
    "mesh = mtf.Mesh(graph, \"my_mesh\")\n",
    "\n",
    "batch_size = 1\n",
    "boxsize=100\n",
    "nc = 64       # Native resolution of the grid\n",
    "\n",
    "# Parameters of the small scales decomposition\n",
    "n_block_x = nblockx\n",
    "n_block_y = nblocky\n",
    "n_block_z = 1\n",
    "halo_size = 8\n",
    "\n",
    "# Parameters of the large scales decomposition\n",
    "downsampling_factor = 2\n",
    "lnc = nc // 2**downsampling_factor \n",
    "\n",
    "\n",
    "# Dimensions of the low resolution grid\n",
    "x_dim = mtf.Dimension(\"nx_lr\", lnc)\n",
    "y_dim = mtf.Dimension(\"ny_lr\", lnc)\n",
    "z_dim = mtf.Dimension(\"nz_lr\", lnc)\n",
    "\n",
    "nx_dim = mtf.Dimension('nx_block', n_block_x)\n",
    "ny_dim = mtf.Dimension('ny_block', n_block_y)\n",
    "nz_dim = mtf.Dimension('nz_block', n_block_z)\n",
    "\n",
    "sx_dim = mtf.Dimension('sx_block', nc//n_block_x)\n",
    "sy_dim = mtf.Dimension('sy_block', nc//n_block_y)\n",
    "sz_dim = mtf.Dimension('sz_block', nc//n_block_z)\n",
    "\n",
    "lx_dim = mtf.Dimension('lx_block', lnc//n_block_x)\n",
    "ly_dim = mtf.Dimension('ly_block', lnc//n_block_y)\n",
    "lz_dim = mtf.Dimension('lz_block', lnc//n_block_z)\n",
    "\n",
    "batch_dim = mtf.Dimension(\"batch\", batch_size)\n",
    "pk_dim = mtf.Dimension(\"npk\", len(plin))\n",
    "pk = mtf.import_tf_tensor(mesh, plin.astype('float32'), shape=[pk_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([Dimension(name='batch', size=1),\n",
       "  Dimension(name='nx_block', size=2),\n",
       "  Dimension(name='ny_block', size=2),\n",
       "  Dimension(name='nz_block', size=1),\n",
       "  Dimension(name='sx_block', size=32),\n",
       "  Dimension(name='sy_block', size=32),\n",
       "  Dimension(name='sz_block', size=64)],\n",
       " [Dimension(name='batch', size=1),\n",
       "  Dimension(name='nx_lr', size=16),\n",
       "  Dimension(name='ny_lr', size=16),\n",
       "  Dimension(name='nz_lr', size=16)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hr_shape = [batch_dim, \n",
    "            nx_dim, ny_dim, nz_dim,\n",
    "            sx_dim, sy_dim, sz_dim]\n",
    "\n",
    "#trying reshapes with this\n",
    "lr_shape2 = [batch_dim, \n",
    "            nx_dim, \n",
    "            lx_dim, y_dim, z_dim]\n",
    "\n",
    "lr_shape = [batch_dim, \n",
    "            x_dim, y_dim, z_dim]\n",
    "\n",
    "hr_shape, lr_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor[reshape_2:0, Shape[batch=1, nx_block=2, ny_block=2, nz_block=1, sx_block=32, sy_block=32, sz_block=64], <dtype: 'float32'>]\n",
      "Tensor[reshape_1:0, Shape[batch=1, nx_block=2, ny_block=2, nz_block=1, sx_block=8, sy_block=8, sz_block=16], <dtype: 'float32'>]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Tensor[reshape_3:0, Shape[batch=1, nx_lr=16, ny_lr=16, nz_lr=16], <dtype: 'float32'>]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "initial_conditions = flowpm.linear_field(nc,          # size of the cube\n",
    "                                         boxsize,     # Physical size of the cube\n",
    "                                         ipklin,      # Initial powerspectrum\n",
    "                                         batch_size=batch_size)\n",
    "initc = tf.reshape(initial_conditions, [1, nblockx, nblocky, 1, nc//nblockx, nc//nblocky, nc])\n",
    "\n",
    "field = mtf.import_tf_tensor(mesh, initc, shape=hr_shape)\n",
    "\n",
    "\n",
    "#commented code not needed to replicate example\n",
    "# for block_size_dim in hr_shape[-3:]:\n",
    "#     field = mtf.pad(field, [halo_size, halo_size], block_size_dim.name)\n",
    "\n",
    "# for blocks_dim, block_size_dim in zip(hr_shape[1:4], field.shape[-3:]):\n",
    "#     field = mesh_ops.halo_reduce(field, blocks_dim, block_size_dim, halo_size)\n",
    "\n",
    "field = mtf.reshape(field, field.shape+[mtf.Dimension('h_dim', 1)])\n",
    "high = field\n",
    "low = mesh_utils.downsample(field, downsampling_factor, antialias=True)\n",
    "\n",
    "low = mtf.reshape(low, low.shape[:-1])\n",
    "high = mtf.reshape(high, high.shape[:-1])\n",
    "print(high)\n",
    "print(low)\n",
    "#commented code not needed to replicate example\n",
    "# for block_size_dim in hr_shape[-3:]:\n",
    "#     low = mtf.slice(low, halo_size//2**downsampling_factor, block_size_dim.size//2**downsampling_factor, block_size_dim.name)\n",
    "\n",
    "low = mtf.reshape(low, lr_shape)\n",
    "\n",
    "#Trying random stuff here\n",
    "# low = mtf.reshape(low, low.shape+[mtf.Dimension('l_dim', 1)])\n",
    "# lshape = low.shape\n",
    "# print(low)\n",
    "# low = mtf.transpose(low, new_shape=lshape[:2]+[lshape[-1]]+lshape[3:-1]+[lshape[2]])\n",
    "# # low = mtf.reshape(low, low.shape[:2]+low.shape[3:5] + lr_shape[2:])\n",
    "# low = mtf.reshape(low, low.shape[:2]+low.shape[3:5] + lr_shape[2:])\n",
    "\n",
    "low"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "NotImplementedError",
     "evalue": "Try first reshaping to insert a new tf dimension, then changing layout. input_shape=Shape[batch=1, nx_block=2, ny_block=2, nz_block=1, sx_block=8, sy_block=8, sz_block=16] output_shape=Shape[batch=1, nx_lr=16, ny_lr=16, nz_lr=16]",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotImplementedError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-11-5f717a1412b9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     10\u001b[0m     mesh_shape, layout_rules, devices)\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mlowering\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLowering\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mmesh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mmesh_impl\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mtf_field\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlowering\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexport_to_tf_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlow\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/tflow2/lib/python3.6/site-packages/mesh_tensorflow/ops.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, graph, mesh_to_impl, autostack)\u001b[0m\n\u001b[1;32m    652\u001b[0m       \u001b[0;31m# tf.logging.info(\"Lowering operation %s\" % op.to_string)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    653\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 654\u001b[0;31m         \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    655\u001b[0m       \u001b[0;32mfor\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         self.add_counter(\n",
      "\u001b[0;32m~/anaconda3/envs/tflow2/lib/python3.6/site-packages/mesh_tensorflow/ops.py\u001b[0m in \u001b[0;36mlower\u001b[0;34m(self, lowering)\u001b[0m\n\u001b[1;32m   4362\u001b[0m             \u001b[0;34m\"Try first reshaping to insert a new tf dimension,\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4363\u001b[0m             \u001b[0;34m\" then changing layout. input_shape=%s output_shape=%s\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4364\u001b[0;31m             % (self.inputs[0].shape, self.outputs[0].shape))\n\u001b[0m\u001b[1;32m   4365\u001b[0m       concat_tensor_axis = old_shape.cumprod_to_tensor_axis(\n\u001b[1;32m   4366\u001b[0m           mesh_axis_to_cumprod_old[mesh_axis])\n",
      "\u001b[0;31mNotImplementedError\u001b[0m: Try first reshaping to insert a new tf dimension, then changing layout. input_shape=Shape[batch=1, nx_block=2, ny_block=2, nz_block=1, sx_block=8, sy_block=8, sz_block=16] output_shape=Shape[batch=1, nx_lr=16, ny_lr=16, nz_lr=16]"
     ]
    }
   ],
   "source": [
    "# Let's have a look!\n",
    "devices = [\"/job:mesh/task:%d\"%i for i in range(cluster.num_tasks(\"mesh\"))]\n",
    "mesh_shape = [(\"row\", nblockx), (\"col\", nblocky)]\n",
    "layout_rules = [(\"nx_lr\", \"row\"), (\"ny_lr\", \"col\"),\n",
    "                (\"nx\", \"row\"), (\"ny\", \"col\"),\n",
    "                (\"nx_block\",\"row\"), (\"ny_block\",\"col\"),\n",
    "               (\"lx_block\",\"row\"), (\"ly_block\",\"col\")]\n",
    "\n",
    "mesh_impl = mtf.placement_mesh_impl.PlacementMeshImpl(\n",
    "    mesh_shape, layout_rules, devices)\n",
    "\n",
    "lowering = mtf.Lowering(graph, {mesh:mesh_impl})\n",
    "\n",
    "tf_field = lowering.export_to_tf_tensor(low)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.Session(\"grpc://localhost:8488\") as sess:\n",
    "    fin_ref = sess.run(tf_field )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 2, 1, 1, 8, 8, 16, 2)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fin_ref.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tflow2",
   "language": "python",
   "name": "tflow2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
